{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training symboloc regression models\n",
    "This notebook illustrates how to use  scripts developed to train symbolic regression models. For more information refer to the [main manuscript](xxx)  \n",
    "\n",
    "To run the following examples, ensure you have installed the right dependencies in your environment:\n",
    "* numpy\n",
    "* pandas\n",
    "* sympy\n",
    "* scikit-learn\n",
    "* autofeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import workflows as wf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data\n",
    "\n",
    "For this example we generate artifical training data from a arbitrarily chosen expression. In your application, however, you will replace this function for a function opening an existing dataset from, e.g. a pickle file, or a csv. Your training data should be in a pandas dataframe of shape (n samples) x (m predictors + target)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- TRAINING DATA -------------------\n",
    "\n",
    "def generate_training_data():\n",
    "    \"\"\"Example function to generate toy training set\"\"\"\n",
    "\n",
    "    npoints = 50\n",
    "    t_coords = np.linspace(243, 330, npoints) #temperature samples\n",
    "    c_coords = np.linspace(0.1, 3, npoints) #concentration samples\n",
    "    b1, b2 = 1, -2e-3 #coefficients\n",
    "\n",
    "    #training dataframe\n",
    "    train_data = pd.DataFrame(data = np.array([np.repeat(t_coords,npoints**2), np.hstack((npoints**2)*(c_coords,))]).T, \n",
    "                            columns=['T', 'c'])\n",
    "\n",
    "    #apply expression to be found via symbolic regression: k = b1*c*t**1.5 + b2*t*c**1.5\n",
    "    train_data['k'] = b1*train_data['c']*train_data['T'].pow(0.5) + b2*train_data['T']*train_data['c'].pow(1.5)\n",
    "    \n",
    "    return train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------  HYPER-PARAMETERS FEATURE GENERATION -------------------\n",
    "\n",
    "#how to scale data. Supported 'standard_nomean', 'standard', 'none'\n",
    "SCALING_TYPE = 'standard_nomean' \n",
    "\n",
    "#whether to leave intercept to vary freely (True) or constrain its value to y0 = 0 (False).\n",
    "FIT_INTERCEPT = False\n",
    "\n",
    "# Autofeat hyperparameter.\n",
    "# number of times features are combined to obtain ever more complex features.\n",
    "# example FEATENG_STEPS = 3 with sqrt transformations will find terms like sqrt(sqrt(sqrt(x)))\n",
    "FEATENG_STEPS = 5\n",
    "\n",
    "# Autofeat hyperparameter.\n",
    "# Units of predictors. Keys must match column names in dataframe. \n",
    "# Ignored predictors are assumed to be dimensionless.\n",
    "UNITS = {\"T\": \"1/K\",\n",
    "        \"c\": \"mol/kg\"}\n",
    "\n",
    "# Autofeat hyperparameter.\n",
    "# Number of iterations for filtering out generated features.\n",
    "FEATSEL_RUNS = 3\n",
    "\n",
    "# Autofeat hyperparameter.\n",
    "# Set of non-linear transformations to be applied to initial predictors.\n",
    "TRANSFORMATIONS = [\"sqrt\", \"sqrt\"]\n",
    "\n",
    "\n",
    "# --------------  HYPER-PARAMETERS FEATURE SELECTION -------------------\n",
    "\n",
    "# n-standard deviations criterion to choose optimal alpha from Cross Validation. \n",
    "# Higher STD_ALPHA lead to sparser solutions.\n",
    "STD_ALPHA = 1 \n",
    "\n",
    "#t-statistic rejection threshold. Coefficients with t-statistic < REJECTION_THR are rejected.\n",
    "REJECTION_THR = 2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AutoFeat] Warning: This just calls fit_transform() but does not return the transformed dataframe.\n",
      "[AutoFeat] It is much more efficient to call fit_transform() instead of fit() and transform()!\n",
      "[AutoFeat] Applying the Pi Theorem\n",
      "[AutoFeat] The 5 step feature engineering process could generate up to 1354 features.\n",
      "[AutoFeat] With 125000 data points this new feature matrix would use about 0.68 gb of space.\n",
      "[feateng] Step 1: transformation of original features\n",
      "[feateng] Generated 2 transformed features from 2 original features - done.\n",
      "[feateng] Step 2: first combination of features\n",
      "[feateng] Generated 6 feature combinations from 6 original feature tuples - done.\n",
      "[feateng] Step 3: transformation of new features\n",
      "[feateng] Generated 6 transformed features from 6 original features - done.\n",
      "[feateng] Step 4: combining old and new features\n",
      "[feateng] Generated 36 feature combinations from 48 original feature tuples - done.\n",
      "[feateng] Step 5: combining new features\n",
      "[feateng] Generated 58 feature combinations from 66 original feature tuples - done.\n",
      "[feateng] Generated altogether 108 new features in 5 steps\n",
      "[feateng] Removing correlated features, as well as additions at the highest level\n",
      "[feateng] Generated a total of 8 additional features\n",
      "[featsel] Scaling data...done.\n",
      "[featsel] Feature selection run 1/3\n",
      "[featsel] Feature selection run 2/3\n",
      "[featsel] Feature selection run 3/3\n",
      "[featsel] 5 features after 3 feature selection runs\n",
      "[featsel] 3 features after correlation filtering\n",
      "[featsel] 2 features after noise filtering\n",
      "[AutoFeat] Computing 1 new features.\n",
      "[AutoFeat]     1/    1 new features ...done.\n",
      "[AutoFeat] Final dataframe with 3 feature columns (1 new).\n",
      "[AutoFeat] Training final regression model.\n",
      "[AutoFeat] Trained model: largest coefficients:\n",
      "-2.127543409731164\n",
      "13.618914 * c\n",
      "0.000061 * T**(3/2)*sqrt(T*c)\n",
      "[AutoFeat] Final score: 0.9994\n",
      "[AutoFeat] Applying the Pi Theorem\n",
      "[AutoFeat] Computing 1 new features.\n",
      "[AutoFeat]     1/    1 new features ...done.\n",
      "[Sparsification] Loop: 0. Current number of features: 3\n",
      "TRAINING COMPLETE\n"
     ]
    }
   ],
   "source": [
    "# ---------------- INSTANTIATE WORKFLOW --------------------------------------\n",
    "training_data = generate_training_data()\n",
    "\n",
    "workflow = wf.WorkflowAF(feateng_steps = FEATENG_STEPS,\n",
    "                        units =  UNITS,\n",
    "                        featsel_runs = FEATSEL_RUNS,\n",
    "                        transformations = TRANSFORMATIONS,\n",
    "                        xtrain = training_data[['c','T']], \n",
    "                        ytrain = training_data['k'], \n",
    "                        scaling_type = SCALING_TYPE,\n",
    "                        stdalpha =  STD_ALPHA, \n",
    "                        rejection_thresshold = REJECTION_THR, \n",
    "                        fit_intercept = FIT_INTERCEPT) \n",
    "\n",
    "# ---------------- RUN TRAINING WORKFLOW --------------------------------------\n",
    "trained_workflow = workflow.run_workflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>stdev</th>\n",
       "      <th>coeff</th>\n",
       "      <th>coeff stdev</th>\n",
       "      <th>coeff |t|</th>\n",
       "      <th>coeff_corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>1.550000</td>\n",
       "      <td>0.854075</td>\n",
       "      <td>11.330666</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>10834.582018</td>\n",
       "      <td>13.266590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T**(3/2)*sqrt(T*c)</th>\n",
       "      <td>97951.021798</td>\n",
       "      <td>36756.952537</td>\n",
       "      <td>2.445561</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>2338.488253</td>\n",
       "      <td>0.000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>286.500000</td>\n",
       "      <td>25.622259</td>\n",
       "      <td>-0.186925</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>178.741006</td>\n",
       "      <td>-0.007295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            mean         stdev      coeff  coeff stdev  \\\n",
       "c                       1.550000      0.854075  11.330666     0.001046   \n",
       "T**(3/2)*sqrt(T*c)  97951.021798  36756.952537   2.445561     0.001046   \n",
       "T                     286.500000     25.622259  -0.186925     0.001046   \n",
       "\n",
       "                       coeff |t|  coeff_corr  \n",
       "c                   10834.582018   13.266590  \n",
       "T**(3/2)*sqrt(T*c)   2338.488253    0.000067  \n",
       "T                     178.741006   -0.007295  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ------------------------- INSPECT SYMBOLIC MODEL --------------------------\n",
    "trained_workflow.coeff_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 6.653328793234911 \\cdot 10^{-5} T^{\\frac{3}{2}} \\sqrt{T c} - 0.0072954162164353764 T + 13.266589527514514 c$"
      ],
      "text/plain": [
       "6.653328793234911e-5*T**(3/2)*sqrt(T*c) - 0.0072954162164353764*T + 13.266589527514514*c"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_workflow.eqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 0.1367177906453799\n",
      "r2: 0.9992615352216608\n",
      "mape: 0.02601023550725349\n"
     ]
    }
   ],
   "source": [
    "# ------------------------- EVALUATE SYMBOLIC MODEL --------------------------\n",
    "import sklearn.metrics as skmetrics \n",
    "\n",
    "y_real = training_data['k']\n",
    "y_hat = trained_workflow.predict(x = training_data[['c','T']])\n",
    "\n",
    "print('mse: {}'.format(skmetrics.mean_squared_error(y_real, y_hat)))\n",
    "print('r2: {}'.format(skmetrics.r2_score(y_real, y_hat)))\n",
    "print('mape: {}'.format(skmetrics.mean_absolute_percentage_error(y_real, y_hat)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
